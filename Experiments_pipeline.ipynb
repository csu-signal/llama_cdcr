{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba8cfa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting model r1_k1\n",
      "3506 2055 2275\n",
      "ecb test\n",
      "& lh_llama && 84.1  & 92.0 & 87.9 && 82.4 & 91.7 & 86.8 && 88.9 & 80.5 & 84.5 && 76.5 & 83.4 & 79.8 && 86.4 \\\n",
      "getting model r1_k0\n",
      "3506 2055 2275\n",
      "ecb test\n",
      "& lh_llama && 79.4  & 92.4 & 85.4 && 79.8 & 93.1 & 85.9 && 89.1 & 76.1 & 82.1 && 73.1 & 81.4 & 77.0 && 84.5 \\\n",
      "getting model r0_k1\n",
      "3506 2055 2275\n",
      "ecb test\n",
      "& lh_llama && 78.2  & 90.6 & 83.9 && 79.4 & 90.2 & 84.4 && 87.9 & 75.4 & 81.2 && 72.4 & 77.2 & 74.7 && 83.2 \\\n",
      "getting model paired\n",
      "3506 2055 2275\n",
      "ecb test\n",
      "& lh_llama && 81.5  & 84.1 & 82.8 && 81.1 & 82.4 & 81.8 && 79.4 & 76.5 & 77.9 && 70.5 & 70.7 & 70.6 && 80.8 \\\n",
      "getting model llama\n",
      "3506 2055 2275\n",
      "ecb test\n",
      "& lh_llama && 84.2  & 76.3 & 80.1 && 82.9 & 73.1 & 77.7 && 67.6 & 77.3 & 72.1 && 67.7 & 62.7 & 65.1 && 76.6 \\\n",
      "getting model gpt\n",
      "3506 2055 2275\n",
      "ecb test\n",
      "& lh_llama && 81.7  & 81.0 & 81.4 && 81.0 & 78.6 & 79.8 && 76.1 & 77.0 & 76.5 && 69.1 & 67.3 & 68.2 && 79.2 \\\n",
      "getting model r1_k1\n",
      "2804 7551 208\n",
      "gvc test\n",
      "& lh_llama && 91.6  & 94.2 & 92.9 && 86.7 & 82.1 & 84.3 && 75.8 & 68.1 & 71.7 && 83.4 & 76.0 & 79.5 && 83.0 \\\n",
      "getting model r1_k0\n",
      "2804 7551 208\n",
      "gvc test\n",
      "& lh_llama && 91.9  & 92.5 & 92.2 && 86.8 & 75.3 & 80.6 && 66.9 & 65.3 & 66.1 && 83.3 & 69.5 & 75.8 && 79.6 \\\n",
      "getting model r0_k1\n",
      "2804 7551 208\n",
      "gvc test\n",
      "& lh_llama && 91.3  & 95.1 & 93.2 && 86.0 & 79.2 & 82.5 && 76.6 & 65.5 & 70.6 && 83.1 & 72.6 & 77.5 && 82.1 \\\n",
      "getting model paired\n",
      "2804 7551 208\n",
      "gvc test\n",
      "& lh_llama && 91.6  & 90.8 & 91.2 && 87.3 & 64.0 & 73.9 && 62.2 & 64.8 & 63.5 && 83.8 & 57.5 & 68.2 && 76.2 \\\n",
      "getting model llama\n",
      "2804 7551 208\n",
      "gvc test\n",
      "& lh_llama && 94.0  & 84.3 & 88.9 && 89.6 & 38.1 & 53.5 && 29.0 & 55.7 & 38.1 && 85.1 & 33.0 & 47.6 && 60.2 \\\n",
      "getting model gpt\n",
      "2804 7551 208\n",
      "gvc test\n",
      "& lh_llama && 88.6  & 81.9 & 85.1 && 82.6 & 35.4 & 49.6 && 27.1 & 41.1 & 32.7 && 76.5 & 26.7 & 39.6 && 55.8 \\\n",
      "getting model r1_k1\n",
      "loading dataset ldc\n",
      "ldc test\n",
      "& lh_llama && 60.6  & 90.6 & 72.6 && 53.3 & 81.5 & 64.5 && 85.3 & 50.0 & 63.0 && 46.6 & 57.7 & 51.6 && 66.7 \\\n",
      "getting model r1_k0\n",
      "loading dataset ldc\n",
      "ldc test\n",
      "& lh_llama && 56.9  & 87.7 & 69.1 && 52.3 & 73.7 & 61.2 && 83.1 & 47.6 & 60.5 && 45.2 & 46.8 & 46.0 && 63.6 \\\n",
      "getting model r0_k1\n",
      "loading dataset ldc\n",
      "ldc test\n",
      "& lh_llama && 60.2  & 88.1 & 71.5 && 53.0 & 73.3 & 61.5 && 81.7 & 48.8 & 61.1 && 45.6 & 49.7 & 47.6 && 64.7 \\\n",
      "getting model paired\n",
      "loading dataset ldc\n",
      "ldc test\n",
      "& lh_llama && 57.5  & 76.4 & 65.6 && 54.4 & 62.4 & 58.1 && 68.0 & 44.4 & 53.7 && 42.6 & 35.0 & 38.4 && 59.1 \\\n",
      "getting model llama\n",
      "loading dataset ldc\n",
      "ldc test\n",
      "& lh_llama && 69.6  & 66.1 & 67.8 && 60.0 & 39.7 & 47.8 && 45.7 & 51.6 & 48.5 && 42.4 & 24.5 & 31.0 && 54.7 \\\n",
      "getting model gpt\n",
      "loading dataset ldc\n",
      "ldc test\n",
      "& lh_llama && 55.7  & 71.5 & 62.6 && 54.4 & 57.7 & 56.0 && 63.0 & 42.8 & 51.0 && 41.8 & 30.3 & 35.1 && 56.5 \\\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "from coval.coval.conll.reader import get_coref_infos\n",
    "from coval.coval.eval.evaluator import evaluate_documents as evaluate\n",
    "from coval.coval.eval.evaluator import muc, b_cubed, ceafe, lea\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils import cluster\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "\n",
    "\n",
    "def read(key, response):\n",
    "    return get_coref_infos('%s' % key, '%s' % response,\n",
    "            False, False, True)\n",
    "\n",
    "\n",
    "def predict_with_inner_monologue(parallel_model, dev_ab,  device, batch_size):\n",
    "    n = dev_ab['input_ids'].shape[0]\n",
    "    indices = list(range(n))\n",
    "    all_scores_ab = []\n",
    "    all_scores_ba = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, n, batch_size), desc='Predicting'):\n",
    "            batch_indices = indices[i: i + batch_size]\n",
    "            scores_ab = forward_ab(parallel_model, dev_ab, device, batch_indices, ann_attn_hidden_logits = False)\n",
    "            #scores_ba = forward_ab(parallel_model, dev_ba, device, batch_indices)\n",
    "            all_scores_ab.append(scores_ab.detach().cpu())\n",
    "            #all_scores_ba.append(scores_ba.detach().cpu())\n",
    "\n",
    "    return torch.cat(all_scores_ab) \n",
    "\n",
    "def get_coreference_scores(dataset_folder, evt_mention_map, all_mention_pairs, dataset, split, heu, similarities, dpos_score_map, out_name, threshold):\n",
    "    curr_mentions = sorted(evt_mention_map.keys())\n",
    "    curr_gold_cluster_map = [(men, evt_mention_map[men]) for men in curr_mentions]\n",
    "    gold_key_file = dataset_folder + f'/evt_gold_{split}.keyfile'\n",
    "    generate_key_file(curr_gold_cluster_map, 'evt', dataset_folder, gold_key_file)\n",
    "\n",
    "    w_dpos_sims = []\n",
    "    for p, sim in zip(all_mention_pairs, similarities):\n",
    "        if tuple(p) in dpos_score_map:\n",
    "            w_dpos_sims.append(dpos_score_map[p][0])\n",
    "        elif (p[1], p[0]) in dpos_score_map:\n",
    "            w_dpos_sims.append(np.mean(dpos_score_map[p[0]]))\n",
    "        else:\n",
    "            w_dpos_sims.append(sim)\n",
    "   \n",
    "\n",
    "    mid2cluster = cluster(curr_mentions, all_mention_pairs, w_dpos_sims, threshold)\n",
    "    system_key_file = dataset_folder + f'/evt_gold_dpos_{out_name}.keyfile'\n",
    "    generate_key_file(mid2cluster.items(), 'evt', dataset_folder, system_key_file)\n",
    "    doc = read(gold_key_file, system_key_file)\n",
    "\n",
    "    mr, mp, mf = np.round(np.round(evaluate(doc, muc), 3) * 100, 1)\n",
    "    br, bp, bf = np.round(np.round(evaluate(doc, b_cubed), 3) * 100, 1)\n",
    "    cr, cp, cf = np.round(np.round(evaluate(doc, ceafe), 3) * 100, 1)\n",
    "    lr, lp, lf = np.round(np.round(evaluate(doc, lea), 3) * 100, 1)\n",
    "    \n",
    "\n",
    "    conf = np.round((mf + bf + cf) / 3, 1)\n",
    "    print(dataset, split)\n",
    "    final_frame = [mr, mp, mf,br, bp, bf,cr, cp, cf,  lr, lp, lf,conf ]\n",
    "    result_string = f'& {heu} && {mr}  & {mp} & {mf} && {br} & {bp} & {bf} && {cr} & {cp} & {cf} && {lr} & {lp} & {lf} && {conf} \\\\'\n",
    "\n",
    "    print(result_string)\n",
    "    return conf, result_string, final_frame\n",
    "\n",
    "\n",
    "\n",
    "def get_final_scores(dataset, split, dpos_score_map, heu='lh_llama', threshold=0.5):\n",
    "    dataset_folder = f'./datasets/{dataset}/'\n",
    "    if dataset == 'ldc':\n",
    "        print(\"loading dataset\", dataset)\n",
    "        evt_mention_map = pickle.load(open(dataset_folder + '/mention_gold_key.pkl', 'rb'))\n",
    "        mps, mps_trans = pickle.load(open(dataset_folder + f'/{heu}/mp_mp_t_test_0.03_new.pkl', 'rb'))\n",
    "        _, _, _, fns = mps_trans\n",
    "        tps, fps, tns, fns_nt = mps\n",
    "      \n",
    "        all_mention_pairs = tps + fps\n",
    "        heu_predictions = np.array([1] * len(tps) + [0] * len(fps))\n",
    "\n",
    "    else:\n",
    "        evt_mention_map = pickle.load(open(dataset_folder + '/mention_gold_key.pkl', 'rb'))\n",
    "        mps, mps_trans = pickle.load(open(f'./datasets/{dataset}/{heu}/mp_mp_t_{split}.pkl', 'rb'))\n",
    "        _, _, _, fns = mps_trans\n",
    "        tps, fps, tns, fns_nt = mps\n",
    "        print(len(tps), len(fps), len(fns))\n",
    "        all_mention_pairs = tps + fps\n",
    "        heu_predictions = np.array([1] * len(tps) + [0] * len(fps))\n",
    "\n",
    "    conf, final_scores, final_frame = get_coreference_scores(dataset_folder, evt_mention_map, all_mention_pairs, dataset, split, heu, heu_predictions, dpos_score_map, out_name=heu, threshold=threshold)\n",
    "    return conf,final_scores, final_frame\n",
    "\n",
    "\n",
    "\n",
    "def get_random_scores(k):\n",
    "   \n",
    "    random_scores = []\n",
    "    for _ in range(k):\n",
    "        k = random.randint(0, 1)# decide on a k each time the loop runs\n",
    "        random_scores.append(k) \n",
    "    return random_scores\n",
    "\n",
    "def get_gpt_scores_aida(): \n",
    "    output = []\n",
    "    output_dict = {}\n",
    "    dataset = 'ldc'\n",
    "    dataset_folder = f'./datasets/{dataset}/'\n",
    "    test_mp_mpt, _ = pickle.load(open(dataset_folder + '/lh/mp_mp_t_test_0.03_new.pkl', 'rb'))\n",
    "    tps_test, fps_test, _,fns_test = test_mp_mpt\n",
    "    test_pairs= list(tps_test + fps_test )\n",
    "    test_labels = [1] * len(tps_test) + [0] * len(fps_test)\n",
    "    bad_idx = pickle.load(open(dataset_folder + f\"/bad_test_indices_{dataset}.pkl\", 'rb')) #indices with faulty mention triggers\n",
    "\n",
    "    test_pairs = [y for x, y in enumerate(test_pairs) if x not in bad_idx]\n",
    "    test_labels = [y for x, y in enumerate(test_labels) if x not in bad_idx]\n",
    "\n",
    "    llama_eval_map  = pickle.load(open(dataset_folder + f\"/ldc_1word.pickle\", 'rb'))\n",
    "\n",
    "    gpt_scores = []\n",
    "    for x in test_pairs:\n",
    "        if x in llama_eval_map.keys():\n",
    "            gpt_scores.append(llama_eval_map[x])\n",
    "    counter_clean = collections.Counter(gpt_scores)\n",
    "    yes_list = ['Yes', 'Yes.', 'yes']\n",
    "\n",
    "    #now preprocess the GPT scores \n",
    "    for i, x in enumerate(gpt_scores):\n",
    "        output.append(x)\n",
    "        if x in yes_list:\n",
    "            output_dict[i] = 1\n",
    "        else:\n",
    "            output_dict[i] = 0\n",
    "    return list(output_dict.values())\n",
    "\n",
    "def save_pair_info(pairs, mention_map, file_name):\n",
    "    sentence_pairs = []\n",
    "    for m1, m2 in pairs:\n",
    "        mention1 = mention_map[m1]\n",
    "        mention2 = mention_map[m2]\n",
    "        sentence_pairs.append((m1, m2, mention1['gold_cluster'], mention2['gold_cluster'], mention1['bert_sentence'], mention2['bert_sentence']))\n",
    "\n",
    "\n",
    "    m1, m2, c1, c2, first, second = zip(*sentence_pairs)\n",
    "    df = pd.DataFrame({'m1': m1, 'm2': m2, 'c1':c1, 'c2':c2, 'first': first, 'second': second})\n",
    "    df.to_csv(file_name)\n",
    "\n",
    "\n",
    "def mention_pair_analysis(dataset, split, heu):\n",
    "    from collections import defaultdict\n",
    "    dataset_folder = f'./datasets/{dataset}/'\n",
    "    mention_map = pickle.load(open(dataset_folder + \"/mention_map.pkl\", 'rb'))\n",
    "    evt_mention_map = {m_id: m for m_id, m in mention_map.items() if m['men_type'] == 'evt' and m['split'] == split}\n",
    "    dpos_map = get_dpos(dataset, heu, split)\n",
    "    (tps, fps, tns, fns), (tps_t, fps_t, tns_t, fns_t) = lh_split(heu, dataset, split, 0.05)\n",
    "\n",
    "    curr_mentions = list(evt_mention_map.keys())\n",
    "    mid2int = {m: i for i, m in enumerate(curr_mentions)}\n",
    "\n",
    "    tps_t = set([tuple(sorted(p)) for p in tps])\n",
    "\n",
    "    p_pos = tps + fps\n",
    "\n",
    "    similarities = np.array([np.mean(dpos_map[p]) if p in p_pos else 0 for p in p_pos])\n",
    "\n",
    "    true_predictions = np.array([1]*len(tps) + [0]*len(fps))\n",
    "    predictions = similarities > 0.5\n",
    "\n",
    "    hard_fps = np.logical_and(predictions, np.logical_not(true_predictions)).nonzero()\n",
    "    hard_fps = [p_pos[i] for i in hard_fps[0]]\n",
    "    print('hard_fps', len(hard_fps))\n",
    "\n",
    "    save_pair_info(hard_fps, mention_map, f'./datasets/{dataset}/analysis/hard_fps_{dataset}.csv')\n",
    "\n",
    "    # clusters = cluster(curr_mentions, mention_pairs=test_pairs, threshold=0.5)\n",
    "\n",
    "    hard_fns = np.logical_and(np.logical_not(predictions), true_predictions).nonzero()\n",
    "    print('hard_fns', len(hard_fps))\n",
    "    hard_fns = [p_pos[i] for i in hard_fns[0]]\n",
    "    save_pair_info(hard_fns, mention_map, f'./datasets/{dataset}/analysis/hard_fns_{dataset}.csv')\n",
    "\n",
    "\n",
    "def get_cluster_size_error(dataset,evt_mention_map_test, clus_map):\n",
    "  \n",
    "    fp_topics = []\n",
    "    values = []\n",
    "    c_to_p = []\n",
    "    cluster = []\n",
    "    cluster_to_pair = defaultdict(int)\n",
    "    gold_clus = []\n",
    "    dataset_folder = f'./datasets/{dataset}'\n",
    "    full_path = f\"{dataset_folder}/lh_prev_scores_full.csv\"\n",
    "    prev_data = pd.read_csv (full_path)\n",
    "    \n",
    "    df_pos = prev_data.loc[(prev_data['coref_label']==1)] \n",
    "    pair_list = df_pos['pairs'].tolist()\n",
    "\n",
    "    for index, x in enumerate(pair_list):\n",
    "        pair = eval(df_pos['pairs'].tolist()[index])\n",
    "        men_1 = pair[0]\n",
    "        men_2 = pair[1]\n",
    "        c_to_p.append((pair, evt_mention_map_test[men_1]['gold_cluster'] ))\n",
    "\n",
    "\n",
    "    result_dict = dict(zip(*zip(*c_to_p)))\n",
    "\n",
    "    \n",
    "    result_dict_large = [x for x, y in result_dict.items() if y in clus_map]\n",
    "    len(result_dict_large)\n",
    "\n",
    "    for index, x in enumerate(pair_list):\n",
    "        pair = eval(df_pos['pairs'].tolist()[index])\n",
    "        men_1 = pair[0]\n",
    "        men_2 = pair[1]\n",
    "        c_to_p.append((pair, evt_mention_map_test[men_1]['gold_cluster'] ))\n",
    "      \n",
    "        if pair in result_dict_large:\n",
    "            values.append((pair,prev_data['scores_lh_prev'][index], prev_data['scores_r1_k1'][index]  ))\n",
    "    df_large_cluster_anal = pd.DataFrame(values, columns=['mention_pair', 'scores_lh_prev', 'scores_r1_k1'])\n",
    "    df_hard_pos_large_clus = df_large_cluster_anal.loc[(df_large_cluster_anal['scores_lh_prev']==0) &\\\n",
    "                                                       (df_large_cluster_anal['scores_r1_k1']==1)]\n",
    "    df_hard_neg_large_clus = df_large_cluster_anal.loc[(df_large_cluster_anal['scores_lh_prev']==1) &\\\n",
    "                                                       (df_large_cluster_anal['scores_r1_k1']==0)]\n",
    "    \n",
    "    df_kd_only = df_large_cluster_anal.loc[(df_large_cluster_anal['scores_r1_k1']==1)]\n",
    "    df_dpos_only = df_large_cluster_anal.loc[(df_large_cluster_anal['scores_lh_prev']==1)]\n",
    "    kd_correct = len(df_hard_pos_large_clus)\n",
    "    dpos_correct =  len(df_hard_neg_large_clus)\n",
    "    kd_only = len(df_kd_only)\n",
    "    dpos_only = len(df_dpos_only)\n",
    "    return kd_correct, dpos_correct, kd_only,dpos_only\n",
    "    \n",
    "def get_cluster_maps(dataset, thres): \n",
    "    \n",
    "    dataset_folder = f'./datasets/{dataset}/'\n",
    "    mention_map = pickle.load(open(dataset_folder + \"/mention_map.pkl\", 'rb'))\n",
    "    evt_mention_map = {m_id: m for m_id, m in mention_map.items() if m['men_type'] == 'evt'}\n",
    "    evt_mention_map_test = {m_id: m for m_id, m in mention_map.items() if m['men_type'] == 'evt' and m['split']=='test'}\n",
    "    inner_monologue_map = pickle.load(open(dataset_folder + f'/im_map_{dataset}.pkl', 'rb'))\n",
    "   \n",
    "    #get the clusters\n",
    "\n",
    "    cluster_set = []\n",
    "    for x, y in evt_mention_map_test.items():\n",
    "        cluster_set.append(y['gold_cluster'])\n",
    "\n",
    "    len(set(cluster_set))\n",
    "\n",
    "    counter = collections.Counter(cluster_set)\n",
    "    #cluster_dict = counter.items()\n",
    "\n",
    "    cluster_dict = dict(counter)\n",
    "    clus_large = {x:y for x, y in cluster_dict.items() if y == thres}  \n",
    "    return clus_large, evt_mention_map_test\n",
    "\n",
    "\n",
    "def save_cluster_plots(df_ecb, df_gvc):\n",
    "    plt.style.use('default')\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    thresholds = df_ecb['c_thres']\n",
    "    values_set1 = df_gvc['kd_correct']\n",
    "    values_set2 = df_gvc['dpos_correct']\n",
    "    values_set3 = df_ecb['kd_only'][0:26] # showing only overlapping cluster sizes\n",
    "    values_set4 = df_ecb['dpos_only'][0:26]\n",
    "    all_values = np.concatenate([values_set1, values_set2, values_set3, values_set4])\n",
    "\n",
    "    colors = plt.cm.viridis(all_values)\n",
    "    \n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    plt.scatter(thresholds, values_set1, label= '$Long_{+ROEC,+KD}$ (GVC)', color='red', marker='o', s=20)\n",
    "    plt.scatter(thresholds, values_set2, label='$Long$ (GVC)', color='green', marker='o', s=20)\n",
    "    plt.scatter(thresholds, values_set3, label='$Long_{+ROEC,+KD}$ (ECB+)', color = 'deepskyblue', marker='^', s=20)\n",
    "    plt.scatter(thresholds, values_set4, label='$Long$ (ECB+)', color = 'mediumorchid', marker='^', s=20)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel('Gold Cluster Thresholds')\n",
    "    plt.ylabel('True Positive Counts')\n",
    "\n",
    "\n",
    "    # Display legend\n",
    "    plt.legend()\n",
    "    #plt.savefig('cluster_plot_final.png', bbox_inches='tight')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_plots_for_clustersize(dataset, cluster_range):\n",
    "    dataset = 'gvc'\n",
    "    kd_error = []\n",
    "    dpos_error = []\n",
    "    kd = []\n",
    "    dpos = []\n",
    "    k_only = []\n",
    "    d_only = []\n",
    "    \n",
    "    cluster_thresholds = [i+1 for i in range(cluster_range)]\n",
    "    for c_thres in tqdm(cluster_thresholds,desc=\"Processing items\", unit=\"item\") :\n",
    "        clus_large, evt_mention_map_test = get_cluster_maps(dataset, c_thres)   \n",
    "        kd_correct, dpos_correct, kd_only,dpos_only = get_cluster_size_error(dataset,evt_mention_map_test, clus_large)\n",
    "        kd_error.append((c_thres, kd_correct, dpos_correct, kd_only,dpos_only))\n",
    "        kd.append((kd_correct, \"L-KD\"))\n",
    "        dpos.append((dpos_correct, \"dpos\"))\n",
    "        k_only.append((kd_only, \"kd-only\"))\n",
    "        d_only.append((dpos_only, \"dpos-only\"))\n",
    "    df_clustering = pd.DataFrame(kd_error, columns=['c_thres', 'kd_correct', 'dpos_correct','kd_only', 'dpos_only'])\n",
    "    return df_clustering\n",
    " \n",
    "def get_llm_scores(dataset, heu, split,model = None):\n",
    "    dataset_folder = f'./datasets/{dataset}/'\n",
    "    #mps, mps_trans = pickle.load(open(f'./datasets/{dataset}/{heu}/mp_mp_t_{split}.pkl', 'rb'))\n",
    "    if dataset == 'ldc':\n",
    "        mps, mps_trans =  pickle.load(open(dataset_folder + f'/{heu}/mp_mp_t_test_0.03_new.pkl', 'rb'))\n",
    "        tps, fps, tns, fns = mps\n",
    "\n",
    "        tps = tps\n",
    "        fps = fps\n",
    "        test_pairs = tps + fps\n",
    "        test_labels = [1]*len(tps) + [0]*len(fps)  \n",
    "        pairs = test_pairs\n",
    "        #scores_ab =  get_gpt_scores_aida()\n",
    "        bad_idx = pickle.load(open(dataset_folder + f\"/bad_test_indices_{dataset}.pkl\", 'rb')) \n",
    "        pairs = [y for x, y in enumerate(pairs) if x not in bad_idx]\n",
    "    else:\n",
    "        test_mp_mpt, _ = pickle.load(open(dataset_folder + f'/{heu}/mp_mp_t_test.pkl', 'rb'))\n",
    "        tps_test, fps_test, _, _ = test_mp_mpt\n",
    "        test_pairs = list(tps_test + fps_test)\n",
    "        test_labels = [1] * len(tps_test) + [0] * len(fps_test)\n",
    "        pairs = test_pairs\n",
    "        \n",
    "\n",
    "\n",
    "    scores1 = pickle.load(open(dataset_folder + f\"/best_scores_llm_cdcr/scores_{model}.pkl\", 'rb'))\n",
    "    if len(scores1)==1:\n",
    "        scores1 = np.array(scores1[0] )\n",
    "    scores2 = scores1\n",
    "    score_map = {}\n",
    "    \n",
    "    \n",
    "    for b, ab, ba in zip(pairs, scores1, scores2):\n",
    "        score_map[tuple(b)] = (float(ab), float(ba))\n",
    "    #print(\"model score map\", len(dpos_map))\n",
    "    return score_map    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    datasets = ['ecb', 'gvc', 'ldc']\n",
    "    dataset = 'ldc'\n",
    "    split = 'test'\n",
    "    heu = 'lh_llama'\n",
    "    # a list of all model types \n",
    "    model_list = ['r1_k1', 'r1_k0', 'r0_k1', 'paired','llama', 'gpt']\n",
    "     \n",
    "    model_dict = {'r1_k0': 'Long+ROEC-KD', 'r0_k1': 'Long-ROEC+KD',\\\n",
    "                  'r1_k1': 'Long+ROEC+KD','paired': 'Long_paired','llama': 'LLaMA2-7B-Chat','gpt': 'GPT3.5Turbo'}\n",
    "    final_exp_results = []\n",
    "    #model_list = ['r1_k1']\n",
    "    for data in datasets: \n",
    "        for model in model_list:\n",
    "            print(\"getting model\", model)\n",
    "            score_map = get_llm_scores(data, heu, split, model = model )\n",
    "\n",
    "            conf,final_scores, final_frame = get_final_scores(data, split, score_map, heu=heu)\n",
    "            model = model_dict[model]\n",
    "            final_frame.insert(0, model)\n",
    "            final_frame.insert(0, data)\n",
    "            final_exp_results.append(final_frame)\n",
    "    return conf,final_scores, final_frame, final_exp_results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conf,final_scores, final_frame,final_exp_results = main()\n",
    "    # Column names for coref metrics \n",
    "    columns = ['dataset', 'model', 'MUC R', 'MUC P', 'MUC F1','B3 R', 'B3 P', 'B3 F1','Ceafe R', 'Ceafe P', 'Ceafe F1','LEA R', 'LEA P', 'LEA F1', 'CoNLL F1' ]\n",
    "\n",
    " \n",
    "    final_results_table = pd.DataFrame(final_exp_results, columns=columns)\n",
    "  \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8294befa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>MUC R</th>\n",
       "      <th>MUC P</th>\n",
       "      <th>MUC F1</th>\n",
       "      <th>B3 R</th>\n",
       "      <th>B3 P</th>\n",
       "      <th>B3 F1</th>\n",
       "      <th>Ceafe R</th>\n",
       "      <th>Ceafe P</th>\n",
       "      <th>Ceafe F1</th>\n",
       "      <th>LEA R</th>\n",
       "      <th>LEA P</th>\n",
       "      <th>LEA F1</th>\n",
       "      <th>CoNLL F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecb</td>\n",
       "      <td>Long+ROEC+KD</td>\n",
       "      <td>84.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.9</td>\n",
       "      <td>82.4</td>\n",
       "      <td>91.7</td>\n",
       "      <td>86.8</td>\n",
       "      <td>88.9</td>\n",
       "      <td>80.5</td>\n",
       "      <td>84.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>83.4</td>\n",
       "      <td>79.8</td>\n",
       "      <td>86.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecb</td>\n",
       "      <td>Long+ROEC-KD</td>\n",
       "      <td>79.4</td>\n",
       "      <td>92.4</td>\n",
       "      <td>85.4</td>\n",
       "      <td>79.8</td>\n",
       "      <td>93.1</td>\n",
       "      <td>85.9</td>\n",
       "      <td>89.1</td>\n",
       "      <td>76.1</td>\n",
       "      <td>82.1</td>\n",
       "      <td>73.1</td>\n",
       "      <td>81.4</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ecb</td>\n",
       "      <td>Long-ROEC+KD</td>\n",
       "      <td>78.2</td>\n",
       "      <td>90.6</td>\n",
       "      <td>83.9</td>\n",
       "      <td>79.4</td>\n",
       "      <td>90.2</td>\n",
       "      <td>84.4</td>\n",
       "      <td>87.9</td>\n",
       "      <td>75.4</td>\n",
       "      <td>81.2</td>\n",
       "      <td>72.4</td>\n",
       "      <td>77.2</td>\n",
       "      <td>74.7</td>\n",
       "      <td>83.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ecb</td>\n",
       "      <td>Long_paired</td>\n",
       "      <td>81.5</td>\n",
       "      <td>84.1</td>\n",
       "      <td>82.8</td>\n",
       "      <td>81.1</td>\n",
       "      <td>82.4</td>\n",
       "      <td>81.8</td>\n",
       "      <td>79.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>77.9</td>\n",
       "      <td>70.5</td>\n",
       "      <td>70.7</td>\n",
       "      <td>70.6</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ecb</td>\n",
       "      <td>LLaMA2-7B-Chat</td>\n",
       "      <td>84.2</td>\n",
       "      <td>76.3</td>\n",
       "      <td>80.1</td>\n",
       "      <td>82.9</td>\n",
       "      <td>73.1</td>\n",
       "      <td>77.7</td>\n",
       "      <td>67.6</td>\n",
       "      <td>77.3</td>\n",
       "      <td>72.1</td>\n",
       "      <td>67.7</td>\n",
       "      <td>62.7</td>\n",
       "      <td>65.1</td>\n",
       "      <td>76.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ecb</td>\n",
       "      <td>GPT3.5Turbo</td>\n",
       "      <td>81.7</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.4</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.6</td>\n",
       "      <td>79.8</td>\n",
       "      <td>76.1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>69.1</td>\n",
       "      <td>67.3</td>\n",
       "      <td>68.2</td>\n",
       "      <td>79.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gvc</td>\n",
       "      <td>Long+ROEC+KD</td>\n",
       "      <td>91.6</td>\n",
       "      <td>94.2</td>\n",
       "      <td>92.9</td>\n",
       "      <td>86.7</td>\n",
       "      <td>82.1</td>\n",
       "      <td>84.3</td>\n",
       "      <td>75.8</td>\n",
       "      <td>68.1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>83.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.5</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gvc</td>\n",
       "      <td>Long+ROEC-KD</td>\n",
       "      <td>91.9</td>\n",
       "      <td>92.5</td>\n",
       "      <td>92.2</td>\n",
       "      <td>86.8</td>\n",
       "      <td>75.3</td>\n",
       "      <td>80.6</td>\n",
       "      <td>66.9</td>\n",
       "      <td>65.3</td>\n",
       "      <td>66.1</td>\n",
       "      <td>83.3</td>\n",
       "      <td>69.5</td>\n",
       "      <td>75.8</td>\n",
       "      <td>79.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gvc</td>\n",
       "      <td>Long-ROEC+KD</td>\n",
       "      <td>91.3</td>\n",
       "      <td>95.1</td>\n",
       "      <td>93.2</td>\n",
       "      <td>86.0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>82.5</td>\n",
       "      <td>76.6</td>\n",
       "      <td>65.5</td>\n",
       "      <td>70.6</td>\n",
       "      <td>83.1</td>\n",
       "      <td>72.6</td>\n",
       "      <td>77.5</td>\n",
       "      <td>82.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gvc</td>\n",
       "      <td>Long_paired</td>\n",
       "      <td>91.6</td>\n",
       "      <td>90.8</td>\n",
       "      <td>91.2</td>\n",
       "      <td>87.3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>62.2</td>\n",
       "      <td>64.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>83.8</td>\n",
       "      <td>57.5</td>\n",
       "      <td>68.2</td>\n",
       "      <td>76.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gvc</td>\n",
       "      <td>LLaMA2-7B-Chat</td>\n",
       "      <td>94.0</td>\n",
       "      <td>84.3</td>\n",
       "      <td>88.9</td>\n",
       "      <td>89.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>53.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.7</td>\n",
       "      <td>38.1</td>\n",
       "      <td>85.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gvc</td>\n",
       "      <td>GPT3.5Turbo</td>\n",
       "      <td>88.6</td>\n",
       "      <td>81.9</td>\n",
       "      <td>85.1</td>\n",
       "      <td>82.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>49.6</td>\n",
       "      <td>27.1</td>\n",
       "      <td>41.1</td>\n",
       "      <td>32.7</td>\n",
       "      <td>76.5</td>\n",
       "      <td>26.7</td>\n",
       "      <td>39.6</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ldc</td>\n",
       "      <td>Long+ROEC+KD</td>\n",
       "      <td>60.6</td>\n",
       "      <td>90.6</td>\n",
       "      <td>72.6</td>\n",
       "      <td>53.3</td>\n",
       "      <td>81.5</td>\n",
       "      <td>64.5</td>\n",
       "      <td>85.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>57.7</td>\n",
       "      <td>51.6</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ldc</td>\n",
       "      <td>Long+ROEC-KD</td>\n",
       "      <td>56.9</td>\n",
       "      <td>87.7</td>\n",
       "      <td>69.1</td>\n",
       "      <td>52.3</td>\n",
       "      <td>73.7</td>\n",
       "      <td>61.2</td>\n",
       "      <td>83.1</td>\n",
       "      <td>47.6</td>\n",
       "      <td>60.5</td>\n",
       "      <td>45.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>63.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ldc</td>\n",
       "      <td>Long-ROEC+KD</td>\n",
       "      <td>60.2</td>\n",
       "      <td>88.1</td>\n",
       "      <td>71.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>61.5</td>\n",
       "      <td>81.7</td>\n",
       "      <td>48.8</td>\n",
       "      <td>61.1</td>\n",
       "      <td>45.6</td>\n",
       "      <td>49.7</td>\n",
       "      <td>47.6</td>\n",
       "      <td>64.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ldc</td>\n",
       "      <td>Long_paired</td>\n",
       "      <td>57.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>65.6</td>\n",
       "      <td>54.4</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>53.7</td>\n",
       "      <td>42.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ldc</td>\n",
       "      <td>LLaMA2-7B-Chat</td>\n",
       "      <td>69.6</td>\n",
       "      <td>66.1</td>\n",
       "      <td>67.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>47.8</td>\n",
       "      <td>45.7</td>\n",
       "      <td>51.6</td>\n",
       "      <td>48.5</td>\n",
       "      <td>42.4</td>\n",
       "      <td>24.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ldc</td>\n",
       "      <td>GPT3.5Turbo</td>\n",
       "      <td>55.7</td>\n",
       "      <td>71.5</td>\n",
       "      <td>62.6</td>\n",
       "      <td>54.4</td>\n",
       "      <td>57.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>51.0</td>\n",
       "      <td>41.8</td>\n",
       "      <td>30.3</td>\n",
       "      <td>35.1</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset           model  MUC R  MUC P  MUC F1  B3 R  B3 P  B3 F1  Ceafe R   \n",
       "0      ecb    Long+ROEC+KD   84.1   92.0    87.9  82.4  91.7   86.8     88.9  \\\n",
       "1      ecb    Long+ROEC-KD   79.4   92.4    85.4  79.8  93.1   85.9     89.1   \n",
       "2      ecb    Long-ROEC+KD   78.2   90.6    83.9  79.4  90.2   84.4     87.9   \n",
       "3      ecb     Long_paired   81.5   84.1    82.8  81.1  82.4   81.8     79.4   \n",
       "4      ecb  LLaMA2-7B-Chat   84.2   76.3    80.1  82.9  73.1   77.7     67.6   \n",
       "5      ecb     GPT3.5Turbo   81.7   81.0    81.4  81.0  78.6   79.8     76.1   \n",
       "6      gvc    Long+ROEC+KD   91.6   94.2    92.9  86.7  82.1   84.3     75.8   \n",
       "7      gvc    Long+ROEC-KD   91.9   92.5    92.2  86.8  75.3   80.6     66.9   \n",
       "8      gvc    Long-ROEC+KD   91.3   95.1    93.2  86.0  79.2   82.5     76.6   \n",
       "9      gvc     Long_paired   91.6   90.8    91.2  87.3  64.0   73.9     62.2   \n",
       "10     gvc  LLaMA2-7B-Chat   94.0   84.3    88.9  89.6  38.1   53.5     29.0   \n",
       "11     gvc     GPT3.5Turbo   88.6   81.9    85.1  82.6  35.4   49.6     27.1   \n",
       "12     ldc    Long+ROEC+KD   60.6   90.6    72.6  53.3  81.5   64.5     85.3   \n",
       "13     ldc    Long+ROEC-KD   56.9   87.7    69.1  52.3  73.7   61.2     83.1   \n",
       "14     ldc    Long-ROEC+KD   60.2   88.1    71.5  53.0  73.3   61.5     81.7   \n",
       "15     ldc     Long_paired   57.5   76.4    65.6  54.4  62.4   58.1     68.0   \n",
       "16     ldc  LLaMA2-7B-Chat   69.6   66.1    67.8  60.0  39.7   47.8     45.7   \n",
       "17     ldc     GPT3.5Turbo   55.7   71.5    62.6  54.4  57.7   56.0     63.0   \n",
       "\n",
       "    Ceafe P  Ceafe F1  LEA R  LEA P  LEA F1  CoNLL F1  \n",
       "0      80.5      84.5   76.5   83.4    79.8      86.4  \n",
       "1      76.1      82.1   73.1   81.4    77.0      84.5  \n",
       "2      75.4      81.2   72.4   77.2    74.7      83.2  \n",
       "3      76.5      77.9   70.5   70.7    70.6      80.8  \n",
       "4      77.3      72.1   67.7   62.7    65.1      76.6  \n",
       "5      77.0      76.5   69.1   67.3    68.2      79.2  \n",
       "6      68.1      71.7   83.4   76.0    79.5      83.0  \n",
       "7      65.3      66.1   83.3   69.5    75.8      79.6  \n",
       "8      65.5      70.6   83.1   72.6    77.5      82.1  \n",
       "9      64.8      63.5   83.8   57.5    68.2      76.2  \n",
       "10     55.7      38.1   85.1   33.0    47.6      60.2  \n",
       "11     41.1      32.7   76.5   26.7    39.6      55.8  \n",
       "12     50.0      63.0   46.6   57.7    51.6      66.7  \n",
       "13     47.6      60.5   45.2   46.8    46.0      63.6  \n",
       "14     48.8      61.1   45.6   49.7    47.6      64.7  \n",
       "15     44.4      53.7   42.6   35.0    38.4      59.1  \n",
       "16     51.6      48.5   42.4   24.5    31.0      54.7  \n",
       "17     42.8      51.0   41.8   30.3    35.1      56.5  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462b7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
